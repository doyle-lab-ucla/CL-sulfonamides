{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436c924-0e87-4e11-ba59-396154fe9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import itertools\n",
    "import shap\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from drfp import DrfpEncoder\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, TextArea\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=6,progress_bar=True)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, r_regression, SelectKBest\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import pearsonr\n",
    "from math import e\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, lightgbm_regression\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d3f14-fd4c-4654-a75d-ce73adfeb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canon(smiles: str=None)->str:\n",
    "    try:\n",
    "        smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles))\n",
    "    except:\n",
    "        pass\n",
    "    return smiles\n",
    "\n",
    "def write_json(in_dict: dict, filename: str):\n",
    "    '''\n",
    "    Write a dictionary to json file\n",
    "    '''\n",
    "\n",
    "    json_obj = json.dumps(in_dict, indent=4, cls=NpEncoder, default=set_default)\n",
    "    with open(filename, 'w') as jo:\n",
    "        jo.write(json_obj)\n",
    "\n",
    "def read_json(filename: str) -> dict:\n",
    "    '''\n",
    "    Read in a json file and return dictionary\n",
    "    '''\n",
    "    with open(filename, 'r') as jo:\n",
    "        json_obj = json.load(jo)\n",
    "    \n",
    "    return json_obj\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def set_default(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    raise TypeError\n",
    "\n",
    "\n",
    "def get_drfp(rxsmi: str=None,\n",
    "            rad=3,\n",
    "            nbits=2048,) -> DataStructs.cDataStructs.ExplicitBitVect:\n",
    "    fps = DrfpEncoder.encode(rxsmi, n_folded_length=nbits,radius=rad)\n",
    "    bv = DataStructs.ExplicitBitVect(len(fps[0]))\n",
    "    bv.SetBitsFromList(np.where(fps[0])[0].tolist()) # Get index of ON bit and set it to BitVect\n",
    "    # return np.asarray(bv, dtype=np.float64)\n",
    "    return bv.ToList()\n",
    "\n",
    "def expand_list_column(df: pd.DataFrame, col_name: str=None) -> tuple[pd.DataFrame,list[str]]:\n",
    "    '''\n",
    "    Break n-length \"bitvector\" column in to n columns\n",
    "    '''\n",
    "    col_values = df[col_name].values.tolist()\n",
    "    new_col_names = [f\"{col_name}_{i}\" for i in range(len(col_values[0]))]\n",
    "    new_df = pd.DataFrame(col_values, columns=new_col_names)\n",
    "    #new_df = pd.DataFrame(np.random.randint(0,1,size=(len(new_df), len(new_col_names))), columns=new_col_names)\n",
    "    new_df = pd.concat([df, new_df], axis=1)\n",
    "    new_df.drop(col_name, axis=1, inplace=True)\n",
    "\n",
    "    return new_df, new_col_names\n",
    "\n",
    "def one_hot_encode(df, columns_to_encode):\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "    ohe_columns = []\n",
    "    for column in columns_to_encode:\n",
    "        # One-hot encode the column using pandas get_dummies function\n",
    "        one_hot_encoded = pd.get_dummies(df[column], prefix=column)\n",
    "        # Add the one-hot encoded columns to the new DataFrame\n",
    "        df_encoded = pd.concat([df_encoded, one_hot_encoded], axis=1)\n",
    "        ohe_columns.append(one_hot_encoded.columns)\n",
    "    \n",
    "    ohe_columns = [col for sublist in ohe_columns for col in sublist]\n",
    "    df_encoded.drop(columns=columns_to_encode, inplace=True)\n",
    "\n",
    "    return df_encoded, ohe_columns\n",
    "\n",
    "def get_molfp(smi: str=None,\n",
    "            radius: int=3,\n",
    "            nbits: int=2048,\n",
    "            features: bool=False,\n",
    "            as_list: bool=False,\n",
    "            AddHs: bool=False) -> DataStructs.cDataStructs.ExplicitBitVect:\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "    except:\n",
    "        print(smi)\n",
    "        return np.nan\n",
    "    if AddHs==True:\n",
    "        mol = Chem.AddHs(mol)\n",
    "\n",
    "    if as_list:\n",
    "        return AllChem.GetMorganFingerprintAsBitVect(mol,radius=radius,nBits=nbits,useFeatures=features).ToList()\n",
    "    else:\n",
    "        return AllChem.GetMorganFingerprintAsBitVect(mol,radius=radius,nBits=nbits,useFeatures=features)\n",
    "\n",
    "def get_reg_metrics(y_true, y_pred):\n",
    "\n",
    "    R2 = r2_score(y_true, y_pred)\n",
    "    MAE = mean_absolute_error(y_true, y_pred)\n",
    "    RMSE = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "    return R2, MAE, RMSE\n",
    "\n",
    "def smiles_to_fingerprints(smiles, radius:int=3, nBits:int=2048, features:bool=True, use_chi:bool=False, tolist:bool=False):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    if tolist == False:\n",
    "        return AllChem.GetHashedMorganFingerprint(mol, radius, nBits=nBits, useFeatures=features, useChirality=False)\n",
    "    else:\n",
    "        return AllChem.GetHashedMorganFingerprint(mol, radius, nBits=nBits, useFeatures=features, useChirality=False).ToList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9bb5b-6fcb-4fa2-a835-ba4aa3468d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features_f_reg(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "def select_features_mi(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "def select_features_rf(X_train, y_train, X_test, y_test,col_list):\n",
    "    forest = RandomForestRegressor(n_jobs=-1,random_state=42)\n",
    "    forest.fit(X_train,y_train)\n",
    "\n",
    "    result = permutation_importance(\n",
    "        forest, X_test, y_test, n_repeats=20, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    forest_importances = pd.Series(result.importances_mean, index=col_list)\n",
    "    return forest_importances\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "# ax.set_title(\"Feature importances using permutation on full model\")\n",
    "# ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "def feat_select(X,Y,type_,cutoff,name):\n",
    "    print('----- '+name+' : '+type_+' ----')\n",
    "    imp_feat = []\n",
    "    # split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "    # feature selection\n",
    "    if type_ =='cf':\n",
    "        X_train_fs, X_test_fs, fs = select_features_f_reg(X_train, y_train, X_test)\n",
    "    elif type_ =='mi': \n",
    "        X_train_fs, X_test_fs, fs = select_features_mi(X_train, y_train, X_test)\n",
    "    elif type_ == 'rf':\n",
    "        fs = select_features_rf(X_train, y_train, X_test, y_test, X.columns.tolist())\n",
    "\n",
    "    # plot the scores\n",
    "    if type_ != 'rf':\n",
    "        plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "        plt.axhline(cutoff,color='k',alpha=0.5,linestyle='--')\n",
    "        plt.show()\n",
    "        # what are scores for the features\n",
    "        for i in range(len(fs.scores_)):\n",
    "            if  fs.scores_[i] > cutoff:\n",
    "                print('Feature %s: %f' % (X.columns[i], fs.scores_[i]))\n",
    "                imp_feat.append(X.columns[i])\n",
    "    else:\n",
    "        plt.bar([i for i in range(len(fs.values))], fs.values)\n",
    "        plt.axhline(cutoff,color='k',alpha=0.5,linestyle='--')\n",
    "        plt.show()\n",
    "        # what are scores for the features\n",
    "        for i in range(len(fs.values)):\n",
    "            if  fs.values[i] > cutoff:\n",
    "                print('Feature %s: %f' % (X.columns[i], fs.values[i]))\n",
    "                imp_feat.append(X.columns[i]) \n",
    "            \n",
    "    return imp_feat\n",
    "\n",
    "#important features compariosn\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "\n",
    "def union(lst1, lst2): \n",
    "    lst3 = set(lst1 + lst2) \n",
    "    return lst3 \n",
    "\n",
    "def print_feat(feat_X,name):\n",
    "    \n",
    "    print('\\nImportant Feature for {0} : '.format(name))\n",
    "    for i,feat in enumerate(feat_X):\n",
    "          print(i+1,feat)\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757a14a-f724-4df7-bf31-869a2a53be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_ranking(X,Y,type_,cutoff,name):\n",
    "    print('----- '+name+' : '+type_+' ----')\n",
    "    imp_feat = []\n",
    "    rows = []\n",
    "    # split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "    # feature selection\n",
    "    if type_ =='cf':\n",
    "        X_train_fs, X_test_fs, fs = select_features_f_reg(X_train, y_train, X_test)\n",
    "    elif type_ =='mi': \n",
    "        X_train_fs, X_test_fs, fs = select_features_mi(X_train, y_train, X_test)\n",
    "    elif type_ == 'rf':\n",
    "        fs = select_features_rf(X_train, y_train, X_test, y_test, X.columns.tolist())\n",
    "\n",
    "    # plot the scores\n",
    "    if type_ != 'rf':\n",
    "        plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "        plt.axhline(cutoff,color='k',alpha=0.5,linestyle='--')\n",
    "        plt.show()\n",
    "        # what are scores for the features\n",
    "        for i in range(len(fs.scores_)):\n",
    "            # if fs.scores_[i] > cutoff:\n",
    "            # print('Feature %s: %f' % (X.columns[i], fs.scores_[i]))\n",
    "            imp_feat.append(X.columns[i])\n",
    "            rows.append([X.columns[i],fs.scores_[i]])\n",
    "    else:\n",
    "        plt.bar([i for i in range(len(fs.values))], fs.values)\n",
    "        plt.axhline(cutoff,color='k',alpha=0.5,linestyle='--')\n",
    "        plt.show()\n",
    "        # what are scores for the features\n",
    "        for i in range(len(fs.values)):\n",
    "            # if fs.values[i] > cutoff:\n",
    "            # print('Feature %s: %f' % (X.columns[i], fs.values[i]))\n",
    "            imp_feat.append(X.columns[i]) \n",
    "            rows.append([X.columns[i],fs.scores_[i]])\n",
    "    \n",
    "    _df = pd.DataFrame(data=rows,columns=['Feature',f'Score_{type_}'])\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca6821-5ae5-406e-b823-fa4f4284e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_prefs = ['Sulfonamide', 'Boronic Acid', 'Catalyst', 'Base', 'Solvent']\n",
    "\n",
    "dft_cols = ['SO2N-dG_deprotonation_gas', 'SO2N-dipole', 'SO2N-electronegativity',\n",
    "                'SO2N-electronic_spatial_extent', 'SO2N-hardness', 'SO2N-homo_energy',\n",
    "                'SO2N-lumo_energy', 'SO2N-molar_mass', 'SO2N-molar_volume',\n",
    "                'SO2N-number_of_atoms',\n",
    "                'SO2N-min_APT_charge', 'SO2N-min_Mulliken_charge',\n",
    "                'SO2N-min_NMR_anisotropy', 'SO2N-min_NMR_shift', 'SO2N-min_NPA_Rydberg',\n",
    "                'SO2N-min_NPA_charge', 'SO2N-min_NPA_total', 'SO2N-min_NPA_valence',\n",
    "                'SO2N-min_VBur', 'SO2N-max_APT_charge', 'SO2N-max_Mulliken_charge',\n",
    "                'SO2N-max_NMR_anisotropy', 'SO2N-max_NMR_shift', 'SO2N-max_NPA_Rydberg',\n",
    "                'SO2N-max_NPA_charge', 'SO2N-max_NPA_core', 'SO2N-max_NPA_total',\n",
    "                'SO2N-max_NPA_valence', 'SO2N-max_VBur', 'SO2N-C_APT_charge',\n",
    "                'SO2N-C_Mulliken_charge', 'SO2N-C_NMR_anisotropy', 'SO2N-C_NMR_shift',\n",
    "                'SO2N-C_NPA_Rydberg', 'SO2N-C_NPA_charge', 'SO2N-C_NPA_core',\n",
    "                'SO2N-C_NPA_total', 'SO2N-C_NPA_valence', 'SO2N-C_VBur',\n",
    "                'SO2N-S_APT_charge', 'SO2N-S_Mulliken_charge', 'SO2N-S_NMR_anisotropy',\n",
    "                'SO2N-S_NMR_shift', 'SO2N-S_NPA_Rydberg', 'SO2N-S_NPA_charge',\n",
    "                'SO2N-S_NPA_core', 'SO2N-S_NPA_total', 'SO2N-S_NPA_valence',\n",
    "                'SO2N-S_VBur', 'SO2N-O_APT_charge', 'SO2N-O_Mulliken_charge',\n",
    "                'SO2N-O_NMR_anisotropy', 'SO2N-O_NMR_shift', 'SO2N-O_NPA_Rydberg',\n",
    "                'SO2N-O_NPA_charge', 'SO2N-O_NPA_core', 'SO2N-O_NPA_total',\n",
    "                'SO2N-O_NPA_valence', 'SO2N-O_VBur', 'SO2N-N_APT_charge',\n",
    "                'SO2N-N_Mulliken_charge', 'SO2N-N_NMR_anisotropy', 'SO2N-N_NMR_shift',\n",
    "                'SO2N-N_NPA_Rydberg', 'SO2N-N_NPA_charge', 'SO2N-N_NPA_core',\n",
    "                'SO2N-N_NPA_total', 'SO2N-N_NPA_valence', 'SO2N-N_VBur',\n",
    "                'SO2N-NPA_charge', 'CSO2N-NPA_charge', 'SO2N-HL-gap', 'SO2N-Omega',\n",
    "                'SO2N-Mulliken_charge', 'CSO2N-Mulliken_charge']\n",
    "\n",
    "solv_cols = ['Fully Soluble', 'Uniform', 'Soluble Class', 'Predicted dGsolv']\n",
    "nmr_cols = ['average d1H shift', 'upfield shift from B(OH)2','remaining B(OH)2', 'broadening']\n",
    "\n",
    "yield_col = ['RAW-MonoYield (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874fbe4-ca07-4642-8ff0-09638769bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfd0ba-eee8-4387-870a-9444ab6afb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'FeatureSelection' not in os.getcwd():\n",
    "    os.chdir('FeatureSelection')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58505b4e-c3ff-4bf0-bacd-25e431368d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/ChanLam_full_dataset_with_features.csv')\n",
    "df = df[df['Set']=='Train'].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa36186-31ca-435b-9340-de8e67013101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[dft_cols+yield_col].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e05bc6-8866-4060-a73e-24ad69c5d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df[dft_cols+yield_col].corr(method='pearson'),\n",
    "           vmin=-1,vmax=1,\n",
    "            cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf31b56-0ab5-4faa-99b5-6b1569801dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = DropCorrelatedFeatures(variables=dft_cols, method='pearson', threshold=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36631d-fdb5-4714-b7d5-6d0b63693556",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[dft_cols]\n",
    "y = df[yield_col].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7e432-ac23-4892-b80f-93787244ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = tr.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73eb2e0-76ae-4507-a2cd-3044c344995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_corrs = tr.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678e42a-5015-4b0a-8176-9fcdb654fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921f0a2-e16a-4c1f-bfbb-a891fcad36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_ranking = feat_ranking(X,y,'mi',0.2,'mi_ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000e62c-8fa8-4bd6-a88f-0fd41a4a2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_feats = {}\n",
    "for featset in list_of_corrs:\n",
    "    _list = list(featset)\n",
    "    _ranks = mi_ranking[mi_ranking['Feature'].isin(_list)].reset_index(drop=False).copy()\n",
    "    \n",
    "    _topfeat = _ranks.sort_values(by='Score_mi',ascending=False).reset_index(drop=True).loc[0,'Feature']\n",
    "    _restfeats = _ranks.sort_values(by='Score_mi',ascending=False).reset_index(drop=True).loc[1:,'Feature'].values.tolist()\n",
    "    ranked_feats[_topfeat] = _restfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218b014-edb2-4b64-8eee-485ba69b23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_corrs = list(itertools.chain.from_iterable(list(ranked_feats.values())))\n",
    "drop_corrs = list(itertools.chain.from_iterable(list(ranked_feats.values())))\n",
    "print(len(drop_corrs))\n",
    "# drop_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5c6b8-5a84-4bae-a3ed-b57cd28d7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr.correlated_feature_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bf7ed-7d87-4995-a399-bbec892eb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e03b8-a319-44ec-a4d3-b23bf7780900",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = list(set(dft_cols+nmr_cols+solv_cols)-set(drop_corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f728d1-8f24-4420-af42-a57ec4ce931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6f3e1-c0ab-4533-b22f-648e14e22698",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_temp = df.copy()\n",
    "scaler = StandardScaler()\n",
    "# X = feat_temp[dft_cols+nmr_cols+solv_cols].copy()\n",
    "X = feat_temp[final_cols]\n",
    "# X = feat_temp.drop(columns=drop_cols).copy()\n",
    "cols = X.columns\n",
    "\n",
    "X[cols] = scaler.fit_transform(X[cols])\n",
    "\n",
    "# Y = feat_temp['MonoYield (%)']\n",
    "Y = feat_temp['RAW-MonoYield (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80698a4c-7e18-4358-86f9-8872e3275e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feat_cf = feat_select(X,Y,'cf',363.939948*0.25,'RAW-MonoYield (%)') # max-val * 0.25\n",
    "imp_feat_mi = feat_select(X,Y,'mi',0.216898*0.5,'RAW-MonoYield (%)')\n",
    "imp_feat_rf = feat_select(X,Y,'rf',0.376505*0.25,'RAW-MonoYield (%)') # max-val * 0.25\n",
    "\n",
    "### Assign to lists\n",
    "feat_int = intersection(imp_feat_cf, imp_feat_mi)\n",
    "feat_un = union(imp_feat_cf, imp_feat_mi)\n",
    "feat_rf = imp_feat_rf\n",
    "\n",
    "print_feat(feat_int,'Intersection')\n",
    "print_feat(feat_un,'Union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d668242-d7c6-4ef2-bbc2-5419bffb19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = '\\t'\n",
    "pca = PCA(n_components=.98)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(f'Explained variance: {pca.explained_variance_ratio_.sum():.1%}')\n",
    "\n",
    "# thrs = 0.35\n",
    "thrs = np.max(np.abs(pca.components_)) * 0.5\n",
    "auto_select = []\n",
    "for i, name in enumerate(pca.feature_names_in_):\n",
    "    fe = []\n",
    "    for pcn in pca.components_:\n",
    "        fe.append(round(pcn[i], 3))\n",
    "\n",
    "    arrfe = np.asarray(fe, dtype=np.float64)\n",
    "    if np.max(np.abs(arrfe)) > thrs:# or arrfe.max() > thrs:\n",
    "        auto_select.append(name)\n",
    "    # print(f'{name:<35}{fe}')\n",
    "\n",
    "print('\\n'+f'Autoselection from {pca.components_.shape[0]} PCs with {thrs = :.3f}')\n",
    "print('\\n'.join(auto_select))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1969b14-f567-4aed-89a4-a5de7bf08708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(n_jobs=-1,\n",
    "                     learning_rate=0.01,\n",
    "                     n_estimators=1024,\n",
    "                     reg_lambda=0.01,\n",
    "                     reg_alpha=0.01,\n",
    "                     random_state=42\n",
    "                     ).fit(X, Y)\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac9d32-785b-49fa-9b34-4f875ba79457",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ad6d9-3ff9-4c4a-a218-7f0b31d6d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sel_idxs = np.where(np.abs(shap_values[0].values)>=0.6)\n",
    "X.columns[np.where(np.abs(shap_values[0].values)>=0.6)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac1e60-89de-45da-b390-9c6bb749244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[shap_sel_idxs].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44969c47-17e9-4c63-a884-87fdbde2b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0][np.where(np.abs(shap_values[0].values)>=0.40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f44c6a-f46c-4e1b-b977-793365d338c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "lightgbm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7a890-6d5d-4d99-af5a-814c07284dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6eaa7-5311-4d9e-b8d2-6043cd17c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "shap.plots.waterfall(shap_values[0][shap_sel_idxs], show=False)\n",
    "# plt.savefig('SHAP_Waterfall_TrainVal_20240416.svg',transparent=True,bbox_inches='tight')\n",
    "plt.savefig('SHAP_Waterfall_TrainVal_20240416.png',transparent=True,bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15068b6e-3a8e-433b-aac2-b2dfa47c77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# shap.plots.beeswarm(shap_values)\n",
    "shap.plots.beeswarm(shap_values, show=False)\n",
    "# plt.savefig('SHAP_Beeswarm_TrainVal_20240416.svg',transparent=True,bbox_inches='tight')\n",
    "plt.savefig('SHAP_Beeswarm_TrainVal_20240416.png',transparent=True,bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7e35d-0dd4-4b1f-9a96-92e42f8b9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(X)\n",
    "shap_interaction_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fda8b-7b11-4fe9-be7b-4e54f0b82d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(shap_interaction_values[0],\n",
    "cmap='coolwarm',vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3801a-7b4e-4965-b7fd-98d998b373df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(shap_interaction_values[0][shap_sel_idxs[0],:][:,shap_sel_idxs[0]],\n",
    "cmap='coolwarm',vmin=-1,vmax=1,annot=True,fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bbac6-2e9c-481e-abbd-bf5e66099ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fead30-28e5-4cd6-ae83-b88eb9453dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_interaction_values[shap_sel_idxs[0],:][:,shap_sel_idxs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef01c45-24b1-4e12-83c5-5aacaf5a77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sel_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d60512-1cd6-4a63-8ea0-2da47730cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(20).reshape((5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df04b8-1360-4c44-a9cb-addbff159c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4daef-e6e6-47ee-b660-2cfa732da6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[0,1,3], :][:, [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c35f88-0412-49e4-81aa-24092cf93498",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {'Only OHE': [],\n",
    "                'All Properties': dft_cols+nmr_cols+solv_cols,\n",
    "                'DFT': dft_cols,\n",
    "                'NoCoLinear': final_cols,\n",
    "                'F-regression': imp_feat_cf,\n",
    "                'MutualInfo': imp_feat_mi,\n",
    "                'F-MI_Intersection': feat_int,\n",
    "                'F-MI_Union': list(feat_un),\n",
    "                'RandomForest': feat_rf,\n",
    "                'PCA': auto_select,\n",
    "                'SHAP': X.columns[shap_sel_idxs].tolist(),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b979e-8fc3-4d18-9afd-8ab914a93887",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(feature_dict, 'Feature_selection.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
